{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRdnLFKf5Ptl"
      },
      "outputs": [],
      "source": [
        "# import library for handle data\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "kee4RYP15YyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./\")"
      ],
      "metadata": {
        "id": "isZ9JaaU5Y1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "1h4paHIy5Y32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data into X and y dataframes\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]"
      ],
      "metadata": {
        "id": "szfQ2omU5fLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the data into X and y dataframes\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "# Convert labels to one-hot encoded format\n",
        "num_classes = len(np.unique(y))\n",
        "y = to_categorical(y, num_classes)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set parameters for LSTM model\n",
        "vocab_size = 10000  # Define your vocabulary size\n",
        "embedding_dim = 128  # Define the embedding dimension\n",
        "max_sequence_length = X.shape[1]  # Set the maximum sequence length based on your data\n",
        "\n",
        "# Build the LSTM model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot accuracy over epochs\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Test'])\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.show()\n",
        "\n",
        "# Calculate precision, recall, and F1-score for each class\n",
        "class_report = classification_report(y_test_classes, y_pred_classes, target_names=[f\"Class {i}\" for i in range(num_classes)], output_dict=True)\n",
        "\n",
        "# Plot precision, recall, and F1-score for each class\n",
        "classes = [f\"Class {i}\" for i in range(num_classes)]\n",
        "metrics = ['precision', 'recall', 'f1-score']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for metric in metrics:\n",
        "    values = [class_report[class_name][metric] for class_name in classes]\n",
        "    plt.plot(classes, values, marker='o', label=metric)\n",
        "\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Precision, Recall, and F1-Score for Each Class')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I5CQabtv5fOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ccY092sd5fQ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}